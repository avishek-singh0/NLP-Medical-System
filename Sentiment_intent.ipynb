{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzAm51cqUc5W"
      },
      "outputs": [],
      "source": [
        "pip install transformers datasets pandas torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiTBqMBFXCuD",
        "outputId": "b79071e7-c211-4d62-dfc9-9c269d122205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/sentiment_intent_data (3).csv\")\n",
        "\n",
        "# Display first few rows\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXmzhGoNalA-",
        "outputId": "fea47158-28ee-4cd2-83c2-054ea2d4a5e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           Statement Sentiment  \\\n",
            "0  I'm a bit worried about my back pain, but I ho...   Anxious   \n",
            "1      I have a fever and headache since last night.   Anxious   \n",
            "2         Should I be concerned about my chest pain?   Anxious   \n",
            "3         My knee has been swollen for two days now.   Anxious   \n",
            "4        I'm scared this could be something serious.   Anxious   \n",
            "\n",
            "   Sentiment_Label               Intent  Intent_Label  \n",
            "0                0  Seeking reassurance             1  \n",
            "1                0   Reporting symptoms             2  \n",
            "2                0  Seeking reassurance             1  \n",
            "3                0   Reporting symptoms             2  \n",
            "4                0   Expressing concern             0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop missing values\n",
        "df = df.dropna(subset=[\"Statement\", \"Sentiment_Label\", \"Intent_Label\"])\n",
        "\n",
        "# Convert labels to integers\n",
        "df[\"Sentiment_Label\"] = df[\"Sentiment_Label\"].astype(int)\n",
        "df[\"Intent_Label\"] = df[\"Intent_Label\"].astype(int)\n",
        "\n",
        "# Print dataset size\n",
        "print(\"Dataset size:\", df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYA4rQEYasGp",
        "outputId": "470cbfed-84af-48b9-d80c-d90ecd759e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: (20, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_data(df, max_length=128):\n",
        "    return tokenizer(\n",
        "        df[\"Statement\"].tolist(),  # Convert text to list\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"  # Convert to PyTorch tensors\n",
        "    )\n",
        "\n",
        "# Tokenize dataset\n",
        "encodings = tokenize_data(df)\n",
        "print(\"Tokenization complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4-qBU-Lawxe",
        "outputId": "da6b3f07-bd48-4e36-d92e-7ed1947a990a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SentimentIntentDataset(Dataset):\n",
        "    def __init__(self, encodings, sentiment_labels, intent_labels):\n",
        "        self.encodings = encodings\n",
        "        self.sentiment_labels = sentiment_labels\n",
        "        self.intent_labels = intent_labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentiment_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = self.sentiment_labels[idx]\n",
        "        item[\"labels\"] = self.intent_labels[idx]\n",
        "        return item\n",
        "\n",
        "# Convert labels to PyTorch tensors\n",
        "sentiment_labels = torch.tensor(df[\"Sentiment_Label\"].tolist())\n",
        "intent_labels = torch.tensor(df[\"Intent_Label\"].tolist())\n",
        "\n",
        "# Create dataset\n",
        "dataset = SentimentIntentDataset(encodings, sentiment_labels, intent_labels)\n",
        "print(\"Dataset created!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQunQ8Wza0p0",
        "outputId": "04240970-0306-475c-e8ba-ac386ab9afe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize train & validation sets\n",
        "train_encodings = tokenize_data(train_df)\n",
        "val_encodings = tokenize_data(val_df)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "train_dataset = SentimentIntentDataset(train_encodings,\n",
        "                                       torch.tensor(train_df[\"Sentiment_Label\"].tolist()),\n",
        "                                       torch.tensor(train_df[\"Intent_Label\"].tolist()))\n",
        "\n",
        "val_dataset = SentimentIntentDataset(val_encodings,\n",
        "                                     torch.tensor(val_df[\"Sentiment_Label\"].tolist()),\n",
        "                                     torch.tensor(val_df[\"Intent_Label\"].tolist()))\n",
        "\n",
        "print(\"Train/Validation split done!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRoIOJc0a59T",
        "outputId": "c11cbd19-e890-4874-df90-436ba36a6bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train/Validation split done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Load models for sentiment & intent (3 classes each)\n",
        "sentiment_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "intent_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "\n",
        "print(\"Models loaded!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvpyHE28a7Yg",
        "outputId": "399213b9-7a30-4a5a-91b5-3eb416367df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Define training parameters\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    report_to=\"none\",  # Disable WandB logging\n",
        ")\n",
        "\n",
        "# Trainer for sentiment classification\n",
        "sentiment_trainer = Trainer(\n",
        "    model=sentiment_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "# Trainer for intent classification\n",
        "intent_trainer = Trainer(\n",
        "    model=intent_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "print(\"Trainers created!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAoqjXCea_FB",
        "outputId": "9cc4b009-3635-4776-9c2a-c6c4539634a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainers created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ”„ Training Sentiment Model...\")\n",
        "sentiment_trainer.train()\n",
        "\n",
        "print(\"ðŸ”„ Training Intent Model...\")\n",
        "intent_trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "w0XkGJM8bCgp",
        "outputId": "e0cdc934-d7b6-4ea5-a1ca-f404932125da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”„ Training Sentiment Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.046536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.031626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.021486</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”„ Training Intent Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.108754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.097593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.092268</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3, training_loss=1.009121338526408, metrics={'train_runtime': 17.0804, 'train_samples_per_second': 2.81, 'train_steps_per_second': 0.176, 'total_flos': 370003243680.0, 'train_loss': 1.009121338526408, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save fine-tuned sentiment model\n",
        "sentiment_model.save_pretrained(\"sentiment_model\")\n",
        "tokenizer.save_pretrained(\"sentiment_model\")\n",
        "\n",
        "# Save fine-tuned intent model\n",
        "intent_model.save_pretrained(\"intent_model\")\n",
        "tokenizer.save_pretrained(\"intent_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UTTbapzb3aZ",
        "outputId": "94bdd6b4-3b97-4fe7-812c-913980e78d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('intent_model/tokenizer_config.json',\n",
              " 'intent_model/special_tokens_map.json',\n",
              " 'intent_model/vocab.txt',\n",
              " 'intent_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Load saved sentiment model\n",
        "sentiment_model = BertForSequenceClassification.from_pretrained(\"sentiment_model\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"sentiment_model\")\n",
        "\n",
        "# Load saved intent model\n",
        "intent_model = BertForSequenceClassification.from_pretrained(\"intent_model\")\n"
      ],
      "metadata": {
        "id": "dvrSIZ-icarF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_text(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "\n",
        "    # Get sentiment prediction\n",
        "    sentiment_outputs = sentiment_model(**inputs)\n",
        "    sentiment_pred = torch.argmax(sentiment_outputs.logits, dim=1).item()\n",
        "\n",
        "    # Get intent prediction\n",
        "    intent_outputs = intent_model(**inputs)\n",
        "    intent_pred = torch.argmax(intent_outputs.logits, dim=1).item()\n",
        "\n",
        "    # Define class labels\n",
        "    sentiment_labels = [\"Anxious\", \"Neutral\", \"Reassured\"]\n",
        "    intent_labels = [\"Seeking reassurance\", \"Reporting symptoms\",\"Expressing concern\"]\n",
        "\n",
        "    return {\n",
        "        \"Sentiment\": sentiment_labels[sentiment_pred],\n",
        "        \"Intent\": intent_labels[intent_pred]\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "text = \"it is not a  result\"\n",
        "output = classify_text(text)\n",
        "\n",
        "# Print result\n",
        "import json\n",
        "print(json.dumps(output, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS2Xu6MKclHQ",
        "outputId": "98c926a5-5744-4232-81b8-43facf9e827c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Sentiment\": \"Neutral\",\n",
            "  \"Intent\": \"Reporting symptoms\"\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}